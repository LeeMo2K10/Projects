
package com.tez;

import java.io.IOException;
import java.util.Set;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.tez.client.CallerContext;
import org.apache.tez.client.TezClient;
import org.apache.tez.dag.api.DAG;
import org.apache.tez.dag.api.DataSinkDescriptor;
import org.apache.tez.dag.api.DataSourceDescriptor;
import org.apache.tez.dag.api.Edge;
import org.apache.tez.dag.api.ProcessorDescriptor;
import org.apache.tez.dag.api.TezConfiguration;
import org.apache.tez.dag.api.TezException;
import org.apache.tez.dag.api.Vertex;
import org.apache.tez.dag.api.client.DAGClient;
import org.apache.tez.dag.api.client.DAGStatus;
import org.apache.tez.dag.api.client.StatusGetOpts;
import org.apache.tez.hadoop.shim.HadoopShim;
import org.apache.tez.hadoop.shim.HadoopShimsLoader;
import org.apache.tez.mapreduce.input.MRInput;
import org.apache.tez.mapreduce.output.MROutput;
import org.apache.tez.runtime.library.conf.OrderedPartitionedKVEdgeConfig;
import org.apache.tez.runtime.library.partitioner.HashPartitioner;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.Sets;

public class WordCount extends Configured implements Tool {
	static String INPUT = "Input";
	static String OUTPUT = "Output";
	static String TOKENIZER = "Tokenizer";
	static String SUMMATION = "Summation";
	TezClient tezClient;
	private HadoopShim hadoopShim;

	private static final Logger LOG = LoggerFactory.getLogger(WordCount.class);

	private DAG createDAG(TezConfiguration tezConf, String inputPath, String outputPath, int numPartitions)
			throws IOException {
		DataSourceDescriptor dataSource = MRInput
				.createConfigBuilder(new Configuration(tezConf), TextInputFormat.class, inputPath).build();
		DataSinkDescriptor dataSink = MROutput
				.createConfigBuilder(new Configuration(tezConf), TextOutputFormat.class, outputPath).build();
		Vertex tokenizerVertex = Vertex.create(TOKENIZER, ProcessorDescriptor.create(TokenProcessor.class.getName()))
				.addDataSource(INPUT, dataSource);
		OrderedPartitionedKVEdgeConfig edgeConf = OrderedPartitionedKVEdgeConfig
				.newBuilder(Text.class.getName(), IntWritable.class.getName(), HashPartitioner.class.getName())
				.setFromConfiguration(tezConf).build();
		Vertex summationVertex = Vertex
				.create(SUMMATION, ProcessorDescriptor.create(SumProcessor.class.getName()), numPartitions)
				.addDataSink(OUTPUT, dataSink);
		DAG dag = DAG.create("WordCount");
		dag.addVertex(tokenizerVertex).addVertex(summationVertex)
				.addEdge(Edge.create(tokenizerVertex, summationVertex, edgeConf.createDefaultEdgeProperty()));
		return dag;
	}

	protected void printUsage() {
		System.err.println("Usage: " + " wordcount in out [numPartitions]");
	}

	protected int validateArgs(String[] otherArgs) {
		if (otherArgs.length < 2 || otherArgs.length > 3) {
			return 2;
		}
		return 0;
	}

	protected int runJob(String[] args, TezConfiguration tezConf, TezClient tezClient) throws Exception {
		DAG dag = createDAG(tezConf, args[0], args[1], args.length == 3 ? Integer.parseInt(args[2]) : 1);
		LOG.info("Running WordCount");
		return runDag(dag, LOG);
	
	}

	private int runDag(DAG dag, Logger log2) throws IOException, TezException, InterruptedException {
		tezClient.waitTillReady();
		CallerContext callerContext = CallerContext.create("TezExamples", "Tez Example DAG: " + dag.getName());
		ApplicationId appId = tezClient.getAppMasterApplicationId();
		if (hadoopShim == null) {
			Configuration conf = (getConf() == null ? new Configuration(false) : getConf());
			hadoopShim = new HadoopShimsLoader(conf).getHadoopShim();
		}
		DAGClient dagClient = tezClient.submitDAG(dag);
		DAGStatus dagStatus;
		Set<StatusGetOpts> getOpts = Sets.newHashSet();
		dagStatus = dagClient.waitForCompletionWithStatusUpdates(getOpts);

		if (dagStatus.getState() != DAGStatus.State.SUCCEEDED) {
			LOG.info("DAG diagnostics: " + dagStatus.getDiagnostics());
			return -1;
		}
		return 0;
	}

	public static void main(String[] args) throws Exception {
		int res = ToolRunner.run(new Configuration(), new WordCount(), args);
		System.exit(res);
	}

	public int run(String[] arg0) throws Exception {
		
		return 0;
	}
}
