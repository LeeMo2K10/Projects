
package com.tez;

import java.io.IOException;
import java.util.Set;

import javax.annotation.Nullable;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.tez.client.CallerContext;
import org.apache.tez.client.TezClient;
import org.apache.tez.common.TezUtilsInternal;
import org.apache.tez.dag.api.DAG;
import org.apache.tez.dag.api.DataSinkDescriptor;
import org.apache.tez.dag.api.DataSourceDescriptor;
import org.apache.tez.dag.api.Edge;
import org.apache.tez.dag.api.ProcessorDescriptor;
import org.apache.tez.dag.api.TezConfiguration;
import org.apache.tez.dag.api.TezException;
import org.apache.tez.dag.api.Vertex;
import org.apache.tez.dag.api.client.DAGClient;
import org.apache.tez.dag.api.client.DAGStatus;
import org.apache.tez.dag.api.client.StatusGetOpts;
import org.apache.tez.hadoop.shim.HadoopShim;
import org.apache.tez.hadoop.shim.HadoopShimsLoader;
import org.apache.tez.mapreduce.input.MRInput;
import org.apache.tez.mapreduce.output.MROutput;
import org.apache.tez.runtime.library.api.TezRuntimeConfiguration;
import org.apache.tez.runtime.library.conf.OrderedPartitionedKVEdgeConfig;
import org.apache.tez.runtime.library.partitioner.HashPartitioner;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.google.common.collect.Sets;

public class WordCount extends Configured implements Tool {
	static String INPUT = "Input";
	static String OUTPUT = "Output";
	static String TOKENIZER = "Tokenizer";
	static String SUMMATION = "Summation";
	TezClient tezClientInternal;
	private HadoopShim hadoopShim;

	private static final Logger LOG = LoggerFactory.getLogger(WordCount.class);

	private DAG createDAG(TezConfiguration tezConf, String inputPath, String outputPath, int numPartitions)
			throws IOException {
		DataSourceDescriptor dataSource = MRInput
				.createConfigBuilder(new Configuration(tezConf), TextInputFormat.class, inputPath).build();
		DataSinkDescriptor dataSink = MROutput
				.createConfigBuilder(new Configuration(tezConf), TextOutputFormat.class, outputPath).build();
		Vertex tokenizerVertex = Vertex.create(TOKENIZER, ProcessorDescriptor.create(TokenProcessor.class.getName()))
				.addDataSource(INPUT, dataSource);
		OrderedPartitionedKVEdgeConfig edgeConf = OrderedPartitionedKVEdgeConfig
				.newBuilder(Text.class.getName(), IntWritable.class.getName(), HashPartitioner.class.getName())
				.setFromConfiguration(tezConf).build();
		Vertex summationVertex = Vertex
				.create(SUMMATION, ProcessorDescriptor.create(SumProcessor.class.getName()), numPartitions)
				.addDataSink(OUTPUT, dataSink);
		DAG dag = DAG.create("WordCount");
		dag.addVertex(tokenizerVertex).addVertex(summationVertex)
				.addEdge(Edge.create(tokenizerVertex, summationVertex, edgeConf.createDefaultEdgeProperty()));
		return dag;
	}

	protected void printUsage() {
		System.err.println("Usage: " + " wordcount in out [numPartitions]");
	}

	protected int validateArgs(String[] otherArgs) {
		if (otherArgs.length < 2 || otherArgs.length > 3) {
			return 2;
		}
		return 0;
	}

	protected int runJob(String[] args, TezConfiguration tezConf, TezClient tezClient) throws Exception {
		DAG dag = createDAG(tezConf, args[0], args[1], args.length == 3 ? Integer.parseInt(args[2]) : 1);
		LOG.info("Running WordCount");
		return runDag(dag, LOG);
	}

	public final int run(String[] args) throws Exception {
		Configuration conf = getConf();
		GenericOptionsParser optionParser = new GenericOptionsParser(conf, args);
		String[] otherArgs = optionParser.getRemainingArgs();
		hadoopShim = new HadoopShimsLoader(conf).getHadoopShim();

		return _execute(otherArgs, null, null);
	}

	public int run(TezConfiguration conf, String[] args, @Nullable TezClient tezClient) throws Exception {
		setConf(conf);
		hadoopShim = new HadoopShimsLoader(conf).getHadoopShim();
		GenericOptionsParser optionParser = new GenericOptionsParser(conf, args);
		String[] otherArgs = optionParser.getRemainingArgs();
		return _execute(otherArgs, conf, tezClient);
	}

	public int runDag(DAG dag, Logger logger) throws TezException, InterruptedException, IOException {
		tezClientInternal.waitTillReady();

		CallerContext callerContext = CallerContext.create("TezExamples", "Tez Example DAG: " + dag.getName());
		ApplicationId appId = tezClientInternal.getAppMasterApplicationId();
		if (hadoopShim == null) {
			Configuration conf = (getConf() == null ? new Configuration(false) : getConf());
			hadoopShim = new HadoopShimsLoader(conf).getHadoopShim();
		}

		if (appId != null) {
			TezUtilsInternal.setHadoopCallerContext(hadoopShim, appId);
			callerContext.setCallerIdAndType(appId.toString(), "TezExampleApplication");
		}
		dag.setCallerContext(callerContext);

		DAGClient dagClient = tezClientInternal.submitDAG(dag);
		Set<StatusGetOpts> getOpts = Sets.newHashSet();
		DAGStatus dagStatus;
		dagStatus = dagClient.waitForCompletionWithStatusUpdates(getOpts);

		if (dagStatus.getState() != DAGStatus.State.SUCCEEDED) {
			logger.info("DAG diagnostics: " + dagStatus.getDiagnostics());
			return -1;
		}
		return 0;
	}

	private int _execute(String[] otherArgs, TezConfiguration tezConf, TezClient tezClient) throws Exception {

		int result = validateArgs(otherArgs);
		if (result != 0) {
			return result;
		}

		if (tezConf == null) {
			tezConf = new TezConfiguration(getConf());
		}
		UserGroupInformation.setConfiguration(tezConf);
		boolean ownTezClient = false;
		if (tezClient == null) {
			ownTezClient = true;
			tezClientInternal = createTezClient(tezConf);
		} else {
			tezClientInternal = tezClient;
		}
		try {
			return runJob(otherArgs, tezConf, tezClientInternal);
		} finally {
			if (ownTezClient && tezClientInternal != null) {
				tezClientInternal.stop();
			}
		}
	}

	private TezClient createTezClient(TezConfiguration tezConf) throws IOException, TezException {
		TezClient tezClient = TezClient.create(getClass().getSimpleName(), tezConf);
		tezClient.start();
		return tezClient;
	}

	public static void main(String[] args) throws Exception {
		int res = ToolRunner.run(new Configuration(), new WordCount(), args);
		System.exit(res);
	}

}
