package com.graph.max;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;

import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.SparkContext;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.graphx.Edge;
import org.apache.spark.graphx.Graph;
import org.apache.spark.graphx.GraphLoader;
import org.apache.spark.storage.StorageLevel;

import scala.Tuple2;
import scala.reflect.ClassTag$;

public class BuildingGraphFromEdgeTuples implements Serializable {

	private static final long serialVersionUID = 1L;
	static Logger log = Logger.getLogger(BuildingGraphFromEdgeTuples.class);

	@SuppressWarnings("unchecked")
	public void get() throws InterruptedException {

		SparkConf conf = new SparkConf().setMaster("local").setAppName("PropertyGraph");
		JavaSparkContext jssc = new JavaSparkContext(conf);

		List<Tuple2<Integer, Integer>> edgeList = new ArrayList<Tuple2<Integer,Integer>>();
		
		edgeList.add(new Tuple2<Integer, Integer>(1, 2));
		edgeList.add(new Tuple2<Integer, Integer>(2, 4));
		edgeList.add(new Tuple2<Integer, Integer>(3, 1));
		edgeList.add(new Tuple2<Integer, Integer>(1, 6));
		edgeList.add(new Tuple2<Integer, Integer>(3, 4));


		JavaRDD<Tuple2<Integer, Integer>> edgeRdd = jssc.parallelize(edgeList);
		

		Integer defaultuser = 5;

		Graph<Integer, Integer> graph = Graph.fromEdgeTuples(arg0, arg1, arg2, arg3, arg4, arg5)

		log.info(graph.vertices().toJavaRDD().collect());

		log.info(graph.ops().numVertices());
		log.info(graph.ops().numEdges());
	}

	public static void main(String[] args) throws InterruptedException {
		BuildingGraphFromEdgeTuples pr = new BuildingGraphFromEdgeTuples();
		pr.get();
	}

}
