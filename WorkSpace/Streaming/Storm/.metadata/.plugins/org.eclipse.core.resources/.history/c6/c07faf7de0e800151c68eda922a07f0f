package com.storm.kafka.mysql;

import java.util.Map;
import java.util.Properties;
import com.google.common.collect.Maps;

import backtype.storm.generated.AlreadyAliveException;
import backtype.storm.generated.InvalidTopologyException;
import backtype.storm.topology.TopologyBuilder;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Values;
import storm.kafka.BrokerHosts;
import storm.kafka.KafkaSpout;
import storm.kafka.SpoutConfig;
import storm.kafka.StringScheme;
import storm.kafka.ZkHosts;
import storm.trident.testing.FixedBatchSpout;

public class Integration {

	public void test() throws AlreadyAliveException, InvalidTopologyException {
		BrokerHosts hosts = new ZkHosts("localhost:9092");
		TopologyBuilder builder = new TopologyBuilder();
		Fields fields = new Fields("key", "message");
		FixedBatchSpout spout = new FixedBatchSpout(fields, 4, new Values("storm", "1"), new Values("trident", "1"),
				new Values("needs", "1"), new Values("javadoc", "1"));
		spout.setCycle(true);
		builder.setSpout("spout", spout, 5);
		// set producer properties.
		Properties props = new Properties();
		props.put("bootstrap.servers", "localhost:9092");
		props.put("acks", "1");
		props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
		props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

		KafkaBolt bolt = new KafkaBolt().withProducerProperties(props)
				.withTopicSelector(new DefaultTopicSelector("test"))
				.withTupleToKafkaMapper(new FieldNameBasedTupleToKafkaMapper());
		builder.setBolt("forwardToKafka", bolt, 8).shuffleGrouping("spout");

		Config conf = new Config();

		StormSubmitter.submitTopology("kafkaboltTest", conf, builder.createTopology());
	}

	public static void main(String[] args) throws AlreadyAliveException, InvalidTopologyException {
		Integration app = new Integration();
		app.test();
	}
}